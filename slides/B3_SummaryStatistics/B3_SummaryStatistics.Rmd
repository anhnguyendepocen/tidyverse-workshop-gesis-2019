---
title: "Summary Statistics"
subtitle: "First inspections - What can we tell about the data?"
author: "Johannes Breuer<br />Stefan JÃ¼nger<br />Thomas Ebel"
date: "2018-05-16"
location: "GESIS, Mannheim, Germany"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "default-fonts", "../footer-header.css", "../mycss.css"]
    nature:
      highlightStyle: "github"
      highlightLines: true
      countIncrementalSlides: false
---
layout: true

```{r setup, include=FALSE}
if (!require(easypackages)) install.packages("easypackages")
library(easypackages)

packages(
  "knitr", "rmarkdown", "tidyverse", "readxl", "datasauRus", "hadley/emo", "DavZim/colorTable",
  prompt = FALSE
)

options(htmltools.dir.version = FALSE)

opts_chunk$set(echo = FALSE, fig.align = "center")#
set.seed(123)

green <- "#a6d96a"
blue  <- "#74add1"
yellow <- "#f4e842"
```

<div class="my-footer">
  <div style="float: left;"><span>`r gsub("<br />", " & ", gsub("<br /><br />|<a.+$", "", metadata$author))`</span></div>
  <div style="float: right;"><span>`r metadata$location`, `r metadata$date`</span></div>
  <div style="text-align: center;"><span>`r gsub(".+<br />", " ", metadata$title)`</span></div>
</div>

---
class: center, middle

<h1>Demystifing unknown knowns</h1>
<h2>What do we know, what don't we know and why do we care?</h2>

---
# Untangling data is hard 
If we look at raw numbers we might have a really hard time at understanding them.

Interpreting single numbers is easy but it's almost impossible, for example, to say which of the following two vectors has

- more variance or
- the lower mean

just by looking at them:

```{r echo=FALSE, results='markup'}
x = sample(x = 18:65, size = 10, replace = TRUE)
y = sample(x = 20:60, size = 10, replace = TRUE)

(x)
(y)
```

---
# And now?

```{r echo=TRUE}
tibble(
  x = sample(x = 18:65, size = 10, replace = TRUE),
  y = sample(x = 20:60, size = 10, replace = TRUE)
) %>% 
  summarize(
    mean_x = mean(x), 
    mean_y = mean(y),
    var_x = sd(x)^2, 
    var_y = sd(y)^2
  )
```

The underlying vectors of the tibble are short. In the real world, vectors are also too long to conveniently look at.


---
<h1> Making sense of data </h1>

To make sense of data we reduce their information to singular values.

.center[
~ 

**That's a simple definition of statistics**

~]

As such, we use summarizing functions of
- location (e.g. the mean),
- spread (e.g. standard deviation),
- shape of distribution (e.g. skewness) and
- relations between variables (e.g. correlation coefficients)

We assume everyone here knows the basics of summary statistics.  

So instead of their boring repetition let's see respective code from the `tidyverse`.


---
# Used data

Our data are from gapminder and the focial variable is income per person (fixed 2000 US$) among 275 countries for the years 1960-2011:


> "Gross Domestic Product per capita in constant 2000 US$. The inflation but not the differences in the cost of living between countries has been taken into account."


```{r echo=TRUE}
capita <- 
  read_excel(
    path = "../../data/gapminder/GDPpercapitaconstant2000US.xlsx", 
    sheet = "Data",
    col_names = TRUE 
    )
```

---
# A first glimpse at the data

```{r}
capita %>% 
  rename(country = 1) %>% 
  glimpse()
```


---
# Getting order in the data

Let's start by reducing the data to 3 countries and converting them to the long format.

```{r capita_long_subset, eval = TRUE, echo = TRUE}
capita_long <- 
  capita %>%
  rename(country = 1) %>%
  filter(
    country %in% 
      c("Germany", "United Kingdom", "United States")
  ) %>%
  gather(-1, key = "year", value = "income") %>%
  arrange(country, year) %>%
  tail()
```



---
# How does it look?

We display only the tail because Germany, which is first in order, has missings up to and including the year 1969.

```{r capita_long_subset_look, echo=FALSE}
capita_long %>%  tail()
```

In any case, information is reduced and the data look much nicer now, doesn't them?


---
# Time for some summary statistics

```{r echo=TRUE}
capita_long %>%
  mutate(change = (income / lag(income) - 1) * 100) %>%
  group_by(country) %>%
  summarise(
    n = sum(!is.na(income)), 
    min_inc = min(income, na.rm = TRUE),
    max_inc = max(income, na.rm = TRUE), 
    diff = max_inc - min_inc, has_na = any(is.na(income)),
    max_change = max(change, na.rm = TRUE)
  )
```

<span class="footnote">
  Note: `change` is change of income in percent to the previous year.
</span>




---
# Searching for extreme values
We may ask in which years the change of income was higher than 2% as the maximum value was `2.1631`

```{r echo=TRUE}
capita_long %>%
  mutate(change = (income / lag(income) - 1) * 100) %>%
  filter(change > 2) 
```

It's been 2010.


---
# Finding the year directly

```{r echo=TRUE}
capita_long %>% 
  mutate(change = (income / lag(income) - 1) * 100) %>%  
  filter(change == max(change, na.rm = TRUE))
```


With this code we see the year in which each country's GDP increased the strongest. Even if we do not care about (other) summary statistics at all.

---
# But, beware: Summary statistics can also be misleading! 

```{r, out.width = "50%"}
include_graphics("./pics/pity_the_fool.jpg")
```


---
<h1> Misleading correlation coefficients </h1>

.column-left-half[
For example, if we do correlation analysis and we encounter a (Pearson's) correlation of close to 0, we often think of relationships as on the right side.

- It's noisy
- There's no observable pattern
- ...it's just a mess and we question our life decision of becoming statisticians
]

.column-right-half[
```{r, out.width = "80%"}
datasauRus::datasaurus_dozen %>% 
  filter(dataset == "h_lines") %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + theme_void()
```
]

---
# Do not despair
The `datasauRus`-package proves to us that various different relations with the same summary statistics are possible.

This one here has **the same correlation coefficient (-0.06, Pearson's)** as on the plot before:

```{r, out.width = "40%"}
datasauRus::datasaurus_dozen %>% 
  filter(dataset == "slant_up") %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  theme_void()
```

.center[There's a trajectory, right? `r ji("dollar")`]

---
# What about this one? (r = -0.06)

```{r}
datasauRus::datasaurus_dozen %>% 
  filter(dataset == "dino") %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + theme_void()
```

---
<h1> What about this one? (r = -0.06) </h1>

.column-left-half[  
```{r, out.width = "60%"}
include_graphics("./pics/rooooar.png")
```
]

.column-right-half[
```{r}
datasauRus::datasaurus_dozen %>% 
  filter(dataset == "dino") %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + theme_void()
```
]

---
# And it goes on and on

All of these 13 datasets have the same means, standard deviations, and Pearson's correlation coefficients.

```{r, out.width = "55%"}
ggplot(
  datasaurus_dozen, 
  aes(
    x = x, 
    y = y, 
    colour = dataset
  )
) +
  geom_point() +
  theme_void() +
  theme(legend.position = "none") +
  facet_wrap(~dataset, ncol=3)
```

---
# Let's prove that to ourselves!

Here's how the data look like
```{r echo=TRUE}
datasauRus::datasaurus_dozen %>% 
  glimpse()
```

---
# Let's prove that to ourselves!
Maybe, in this case, it's more convient to count the data points in each dataset.

```{r echo=TRUE}
datasauRus::datasaurus_dozen %>% 
  select(dataset) %>% 
  table()
```

---
# Are the points simply identical across the datasets?

Here's how it works:

```{r echo=TRUE}
x <- c(1,2,3,4)
x2 <- c(4,3,2,1)
identical(sort(x),sort(x2))
```


---
# Are the points simply identical across the datasets?

And for example, for the dataset `dino` and `away`:

```{r echo=TRUE}
dino <- 
  datasaurus_dozen %>%
  filter(dataset == "dino")

away <- 
  datasaurus_dozen %>%
  filter(dataset == "away")

identical(sort(dino$x), sort(away$x))
```


---
# Let's compute the statistics

<span class="footnote">
  <span class="red bold">*</span> Important footnote
</span>

```{r datasaurus_solution, eval = FALSE, echo=TRUE}
datasaurus_dozen %>% 
  group_by(dataset) %>%
  summarise(
    n = n(), 
    mean_x = mean(x), 
    mean_y = mean(y), 
    sd_x = sd(x), 
    sd_y = sd(y), 
    corr = cor(x, y, method = "pearson")
  )
```

---
# Let's compute the statistics

```{r ref.label = "datasaurus_solution", echo=FALSE}
```

---

class: center, middle

# [Exercise](https://jobreu.github.io/tidyverse-workshop-gesis-2019/exercises/tidy_data_exercises_question.html) time `r ji("weight_lifting_woman")``r ji("muscle")``r ji("running_man")``r ji("biking_man")`

## [Solutions](https://jobreu.github.io/tidyverse-workshop-gesis-2019/solutions/tidy_data_exercises_solution.html)



---

<h2> Your turn! Excercises :) </h2>

```{r echo=TRUE}
gapminder_example <- 
  readxl::read_excel(
    path = "../data/GDPpercapitaconstant2000US.xlsx",
    sheet = "Data")
gapminder_example %>% select(1:4) %>% head(n = 4)
```

Task: Compute the mean GDP of 1960-1969 over all countries?

---

Solution

```{r echo=TRUE}
gapminder_example %>% 
  mutate(country = `Income per person (fixed 2000 US$)`) %>% 
  select(country, starts_with("196")) %>% 
  gather(-1, key = "year", value = "GDP") %>%
  filter(!is.na(GDP)) %>% 
  arrange(year, GDP) %>%
  group_by(year) %>% 
  summarise(`GDP_over_all_countries` = mean(GDP))
```

---
class: center, middle

<h2> Thanks!</h2>

Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).

The chakra comes from [remark.js](https://remarkjs.com), [**knitr**](http://yihui.name/knitr), and [R Markdown](https://rmarkdown.rstudio.com).

