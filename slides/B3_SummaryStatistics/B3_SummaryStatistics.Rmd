---
title: "Data Wrangling & Exploration with the Tidyverse in R"
subtitle: "Summary Statistics"
author: "Johannes Breuer<br />Stefan JÃ¼nger<br />Thomas Ebel"
date: "2018-05-16"
location: "GESIS, Mannheim, Germany"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "default-fonts", "../footer-header.css", "../mycss.css"]
    nature:
      highlightStyle: "github"
      highlightLines: true
      countIncrementalSlides: false
---
layout: true

```{r setup, include=FALSE}
if (!require(easypackages)) install.packages("easypackages")
library(easypackages)

packages(
  "knitr", "rmarkdown", "tidyverse", "readxl", "datasauRus", "hadley/emo", "DavZim/colorTable",
  prompt = FALSE
)

options(htmltools.dir.version = FALSE)

opts_chunk$set(echo = FALSE, fig.align = "center")#
set.seed(123)

green <- "#a6d96a"
blue  <- "#74add1"
yellow <- "#f4e842"
```

<div class="my-footer">
  <div style="float: left;"><span>`r gsub("<br />", " & ", gsub("<br /><br />|<a.+$", "", metadata$author))`</span></div>
  <div style="float: right;"><span>`r metadata$location`, `r metadata$date`</span></div>
  <div style="text-align: center;"><span>`r gsub(".+<br />", " ", metadata$title)`</span></div>
</div>

---
class: center, middle

# Demystifing unknown knowns
## What do we know, what don't we know and why do we care?

---

# Untangling data is hard 

If we look at raw numbers, we might have a hard time understanding them.

Interpreting single numbers is easy, but it's almost impossible, for example, to say which of the following two vectors has

- more variance or
- the lower mean

just by looking at them:

```{r echo=FALSE, results='markup'}
x = sample(x = 18:65, size = 10, replace = TRUE)
y = sample(x = 20:60, size = 10, replace = TRUE)

(x)
(y)
```

---
# And now?

```{r echo=TRUE}
tibble(
  x = sample(x = 18:65, size = 10, replace = TRUE),
  y = sample(x = 20:60, size = 10, replace = TRUE)
) %>% 
  summarize(
    mean_x = mean(x), 
    mean_y = mean(y),
    var_x = sd(x)^2, 
    var_y = sd(y)^2
  )
```

The underlying vectors of this tibble are short. In the real world, vectors are also tend to be too long to be eyeballed conveniently.

---

# Making sense of data

To make sense of data we reduce their information to unique values.

.center[
~ 

**That's a simple definition of summary statistics**

~]

As such, we use summarizing functions of
- location (e.g., the mean),
- spread (e.g., standard deviation),
- the shape of the distribution (e.g., skewness), and
- relations between variables (e.g., correlation coefficients)

We assume everyone here knows the basics of summary statistics. So instead of their repeating them, let's see how to create them with tools from the `tidyverse`.

---

# Gapminder data

As in many of the previous exercises we will use data from [*Gapminder*](https://www.gapminder.org/) in the following. Our focal variable is income per person (fixed 2000 US$) in 275 countries for the years 1960-2011:


> "Gross Domestic Product per capita in constant 2000 US$. The inflation but not the differences in the cost of living between countries has been taken into account."


```{r echo=TRUE}
capita <- 
  read_excel(
    path = "../../data/gapminder/GDPpercapitaconstant2000US.xlsx", 
    sheet = "Data",
    col_names = TRUE 
    )
```

---

# A first glimpse at the data

```{r}
capita %>% 
  rename(country = 1) %>% 
  glimpse()
```

---

# Tidying & wrangling the data

Let's start by reducing the data to 3 countries and converting them to the long format.

```{r capita_long_subset, eval = TRUE, echo = TRUE}
capita_long <- 
  capita %>%
  rename(country = 1) %>%
  filter(
    country %in% 
      c("Germany", "United Kingdom", "United States")
  ) %>%
  gather(-1, key = "year", value = "income") %>%
  arrange(country, year) %>%
  tail()
```

---

# How does it look?

We display only the tail (last 6 observations here) because Germany, which appears at the head of the new dataframe, has missings up to and including the year 1969.

```{r capita_long_subset_look, echo=FALSE}
capita_long %>%  tail()
```

In any case, information is reduced, and the data look much nicer now.

---

# Time for some summary statistics

```{r echo=TRUE}
capita_long %>%
  mutate(change = (income / lag(income) - 1) * 100) %>%
  group_by(country) %>%
  summarise(
    n = sum(!is.na(income)), 
    min_inc = min(income, na.rm = TRUE),
    max_inc = max(income, na.rm = TRUE), 
    diff = max_inc - min_inc, has_na = any(is.na(income)),
    max_change = max(change, na.rm = TRUE)
  )
```

This code might be a bit difficult to understand for you now, but don't worry: We will discuss the individual functions included here in the following.

<span class="footnote">
  Note: `change` is the change in income from the previous measurement in percent.
</span>

---

# Searching for extreme values

We may, for example, want to find years in which the change in income was higher than 2% (as the maximum value was `2.16`).

```{r echo=TRUE}
capita_long %>%
  mutate(change = (income / lag(income) - 1) * 100) %>%
  filter(change > 2) 
```

---

# Finding the year with the maximum value

```{r echo=TRUE}
capita_long %>% 
  mutate(change = (income / lag(income) - 1) * 100) %>%  
  filter(change == max(change, na.rm = TRUE))
```


With this code, we see data for the year in the country's GDP showed the highest increase. This is helpful even if we do not care about (other) summary statistics at all.

---

# But, beware: Summary statistics can also be misleading! 

```{r, out.width = "50%"}
include_graphics("./pics/pity_the_fool.jpg")
```


---

# Misleading correlation coefficients

.column-left-half[
For example, if we do correlation analysis and we encounter a (Pearson's) correlation coefficient close to 0, we often think of relationships as pictured on the right side.

- It's noisy

- There's no observable pattern

- ...it's just a mess, and we question our life decision of working with data
]

.column-right-half[
```{r, out.width = "80%"}
datasauRus::datasaurus_dozen %>% 
  filter(dataset == "h_lines") %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + theme_void()
```
]

---
# Do not despair
The [`datasauRus` package](https://github.com/lockedata/datasauRus) proves to us that various different relations with the same summary statistics are possible.

This dataset has **the same correlation coefficient (-0.06, Pearson's)** as the one in the previous plot:

```{r, out.width = "40%"}
datasauRus::datasaurus_dozen %>% 
  filter(dataset == "slant_up") %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  theme_void()
```

.center[But there's a trajectory, right? `r ji("dollar")`]

---

# What about this one? (r = -0.06)

```{r}
datasauRus::datasaurus_dozen %>% 
  filter(dataset == "dino") %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + theme_void()
```

---

# What about this one? (r = -0.06)

.column-left-half[  
```{r, out.width = "60%"}
include_graphics("./pics/rooooar.png")
```
]

.column-right-half[
```{r}
datasauRus::datasaurus_dozen %>% 
  filter(dataset == "dino") %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + theme_void()
```
]

---
# And it goes on and on...

All of these 13 datasets have the same means, standard deviations, and Pearson's correlation coefficients.

```{r, out.width = "55%"}
ggplot(
  datasaurus_dozen, 
  aes(
    x = x, 
    y = y, 
    colour = dataset
  )
) +
  geom_point() +
  theme_void() +
  theme(legend.position = "none") +
  facet_wrap(~dataset, ncol=3)
```

---

# Let's prove that to ourselves!

Here's what the data look like
```{r echo=TRUE}
datasauRus::datasaurus_dozen %>% 
  glimpse()
```

---

# Let's prove that to ourselves!
Maybe, in this case, it's more convenient to count the data points in each dataset.

```{r echo=TRUE}
datasauRus::datasaurus_dozen %>% 
  select(dataset) %>% 
  table()
```

---
# Are the points identical across the datasets?

Here's how it works:

```{r echo=TRUE}
x <- c(1,2,3,4)
x2 <- c(4,3,2,1)
identical(sort(x),sort(x2))
```


---
# Are the points identical across the datasets?

And for example, for the dataset `dino` and `away`:

```{r echo=TRUE}
dino <- 
  datasaurus_dozen %>%
  filter(dataset == "dino")

away <- 
  datasaurus_dozen %>%
  filter(dataset == "away")

identical(sort(dino$x), sort(away$x))
```


---
# Let's compute the summary statistics

```{r datasaurus_solution, eval = FALSE, echo=TRUE}
datasaurus_dozen %>% 
  group_by(dataset) %>%
  summarise(
    n = n(), 
    mean_x = mean(x), 
    mean_y = mean(y), 
    sd_x = sd(x), 
    sd_y = sd(y), 
    corr = cor(x, y, method = "pearson")
  )
```

---
# Let's compute the summary statistics

```{r ref.label = "datasaurus_solution", echo=FALSE}
```

---

class: center, middle

# [Exercise](https://jobreu.github.io/tidyverse-workshop-gesis-2019/exercises/B3_SummaryStatistics_exercises_question.html) time `r ji("weight_lifting_woman")``r ji("muscle")``r ji("running_man")``r ji("biking_man")`

## [Solutions](https://jobreu.github.io/tidyverse-workshop-gesis-2019/solutions/B3_SummaryStatistics_exercises_solution.html)